# typed: true

# DO NOT EDIT MANUALLY
# This is an autogenerated file for types exported from the `concurrent-ruby` gem.
# Please instead update this file by running `bin/tapioca gem concurrent-ruby`.

# {include:file:README.md}
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/engine.rb#1
module Concurrent
  extend ::Concurrent::Utility::EngineDetector
  extend ::Concurrent::Utility::NativeExtensionLoader
  extend ::Logger::Severity
  extend ::Concurrent::Concern::Logging
  extend ::Concurrent::Concern::Deprecation

  private

  # Returns the current time as tracked by the application monotonic clock.
  #
  # @param unit [Symbol] the time unit to be returned, can be either
  #   :float_second, :float_millisecond, :float_microsecond, :second,
  #   :millisecond, :microsecond, or :nanosecond default to :float_second.
  # @return [Float] The current monotonic time since some unspecified
  #   starting point
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/monotonic_time.rb#15
  def monotonic_time(unit = T.unsafe(nil)); end

  class << self
    # @return [Logger] Logger with provided level and output.
    #
    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/logging.rb#37
    def create_simple_logger(level = T.unsafe(nil), output = T.unsafe(nil)); end

    # @deprecated
    # @return [Logger] Logger with provided level and output.
    #
    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/logging.rb#69
    def create_stdlib_logger(level = T.unsafe(nil), output = T.unsafe(nil)); end

    # Disables AtExit handlers including pool auto-termination handlers.
    # When disabled it will be the application programmer's responsibility
    # to ensure that the handlers are shutdown properly prior to application
    # exit by calling `AtExit.run` method.
    #
    # @deprecated Has no effect since it is no longer needed, see https://github.com/ruby-concurrency/concurrent-ruby/pull/841.
    # @note this option should be needed only because of `at_exit` ordering
    #   issues which may arise when running some of the testing frameworks.
    #   E.g. Minitest's test-suite runs itself in `at_exit` callback which
    #   executes after the pools are already terminated. Then auto termination
    #   needs to be disabled and called manually after test-suite ends.
    # @note This method should *never* be called
    #   from within a gem. It should *only* be used from within the main
    #   application and even then it should be used only when necessary.
    #
    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/configuration.rb#48
    def disable_at_exit_handlers!; end

    # General access point to global executors.
    #
    # @param executor_identifier [Symbol, Executor] symbols:
    #   - :fast - {Concurrent.global_fast_executor}
    #   - :io - {Concurrent.global_io_executor}
    #   - :immediate - {Concurrent.global_immediate_executor}
    # @return [Executor]
    #
    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/configuration.rb#83
    def executor(executor_identifier); end

    # Global thread pool optimized for short, fast *operations*.
    #
    # @return [ThreadPoolExecutor] the thread pool
    #
    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/configuration.rb#55
    def global_fast_executor; end

    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/configuration.rb#66
    def global_immediate_executor; end

    # Global thread pool optimized for long, blocking (IO) *tasks*.
    #
    # @return [ThreadPoolExecutor] the thread pool
    #
    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/configuration.rb#62
    def global_io_executor; end

    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/logging.rb#109
    def global_logger; end

    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/logging.rb#113
    def global_logger=(value); end

    # Global thread pool user for global *timers*.
    #
    # @return [Concurrent::TimerSet] the thread pool
    #
    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/configuration.rb#73
    def global_timer_set; end

    # Returns the current time as tracked by the application monotonic clock.
    #
    # @param unit [Symbol] the time unit to be returned, can be either
    #   :float_second, :float_millisecond, :float_microsecond, :second,
    #   :millisecond, :microsecond, or :nanosecond default to :float_second.
    # @return [Float] The current monotonic time since some unspecified
    #   starting point
    #
    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/monotonic_time.rb#15
    def monotonic_time(unit = T.unsafe(nil)); end

    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/configuration.rb#87
    def new_fast_executor(opts = T.unsafe(nil)); end

    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/configuration.rb#98
    def new_io_executor(opts = T.unsafe(nil)); end

    # Number of physical processor cores on the current system. For performance
    # reasons the calculated value will be memoized on the first call.
    #
    # On Windows the Win32 API will be queried for the `NumberOfCores from
    # Win32_Processor`. This will return the total number "of cores for the
    # current instance of the processor." On Unix-like operating systems either
    # the `hwprefs` or `sysctl` utility will be called in a subshell and the
    # returned value will be used. In the rare case where none of these methods
    # work or an exception is raised the function will simply return 1.
    #
    # @return [Integer] number physical processor cores on the current system
    # @see https://github.com/grosser/parallel/blob/4fc8b89d08c7091fe0419ca8fba1ec3ce5a8d185/lib/parallel.rb
    # @see http://msdn.microsoft.com/en-us/library/aa394373(v=vs.85).aspx
    # @see http://www.unix.com/man-page/osx/1/HWPREFS/
    # @see http://linux.die.net/man/8/sysctl
    #
    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/processor_counter.rb#107
    def physical_processor_count; end

    # Number of processors seen by the OS and used for process scheduling. For
    # performance reasons the calculated value will be memoized on the first
    # call.
    #
    # When running under JRuby the Java runtime call
    # `java.lang.Runtime.getRuntime.availableProcessors` will be used. According
    # to the Java documentation this "value may change during a particular
    # invocation of the virtual machine... [applications] should therefore
    # occasionally poll this property." Subsequently the result will NOT be
    # memoized under JRuby.
    #
    # Otherwise Ruby's Etc.nprocessors will be used.
    #
    # @return [Integer] number of processors seen by the OS or Java runtime
    # @see http://docs.oracle.com/javase/6/docs/api/java/lang/Runtime.html#availableProcessors()
    #
    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/processor_counter.rb#86
    def processor_count; end

    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/processor_counter.rb#68
    def processor_counter; end

    # Use logger created by #create_simple_logger to log concurrent-ruby messages.
    #
    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/logging.rb#63
    def use_simple_logger(level = T.unsafe(nil), output = T.unsafe(nil)); end

    # Use logger created by #create_stdlib_logger to log concurrent-ruby messages.
    #
    # @deprecated
    #
    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/logging.rb#96
    def use_stdlib_logger(level = T.unsafe(nil), output = T.unsafe(nil)); end
  end
end

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb#10
class Concurrent::AbstractExecutorService < ::Concurrent::Synchronization::LockableObject
  include ::Logger::Severity
  include ::Concurrent::Concern::Logging
  include ::Concurrent::ExecutorService
  include ::Concurrent::Concern::Deprecation

  # Create a new thread pool.
  #
  # @return [AbstractExecutorService] a new instance of AbstractExecutorService
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb#23
  def initialize(opts = T.unsafe(nil), &block); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb#72
  def auto_terminate=(value); end

  # @return [Boolean]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb#67
  def auto_terminate?; end

  # Returns the value of attribute fallback_policy.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb#18
  def fallback_policy; end

  # @raise [NotImplementedError]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb#42
  def kill; end

  # Returns the value of attribute name.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb#20
  def name; end

  # @return [Boolean]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb#52
  def running?; end

  # @raise [NotImplementedError]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb#37
  def shutdown; end

  # @return [Boolean]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb#62
  def shutdown?; end

  # @return [Boolean]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb#57
  def shuttingdown?; end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb#32
  def to_s; end

  # @raise [NotImplementedError]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb#47
  def wait_for_termination(timeout = T.unsafe(nil)); end

  private

  # Returns an action which executes the `fallback_policy` once the queue
  # size reaches `max_queue`. The reason for the indirection of an action
  # is so that the work can be deferred outside of synchronization.
  #
  # @param args [Array] the arguments to the task which is being handled.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb#85
  def fallback_action(*args); end

  # @return [Boolean]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb#126
  def ns_auto_terminate?; end

  # @raise [NotImplementedError]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb#106
  def ns_execute(*args, &task); end

  # Callback method called when the executor has been killed.
  # The default behavior is to do nothing.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb#122
  def ns_kill_execution; end

  # Callback method called when an orderly shutdown has completed.
  # The default behavior is to signal all waiting threads.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb#114
  def ns_shutdown_execution; end
end

# The set of possible fallback policies that may be set at thread pool creation.
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/abstract_executor_service.rb#15
Concurrent::AbstractExecutorService::FALLBACK_POLICIES = T.let(T.unsafe(nil), Array)

# Define update methods that use direct paths
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic_reference/atomic_direct_update.rb#9
module Concurrent::AtomicDirectUpdate
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic_reference/atomic_direct_update.rb#15
  def try_update; end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic_reference/atomic_direct_update.rb#24
  def try_update!; end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic_reference/atomic_direct_update.rb#10
  def update; end
end

# Special "compare and set" handling of numeric values.
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic_reference/numeric_cas_wrapper.rb#7
module Concurrent::AtomicNumericCompareAndSetWrapper
  # Atomically sets the value to the given updated value if
  # the current value == the expected value.
  #
  # that the actual value was not equal to the expected value.
  #
  # @param old_value [Object] the expected value
  # @param new_value [Object] the new value
  # @return [Boolean] `true` if successful. A `false` return indicates
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic_reference/numeric_cas_wrapper.rb#10
  def compare_and_set(old_value, new_value); end
end

# An object reference that may be updated atomically. All read and write
# operations have java volatile semantic.
#
#
# ## Thread-safe Variable Classes
#
# Each of the thread-safe variable classes is designed to solve a different
# problem. In general:
#
# * *{Concurrent::Agent}:* Shared, mutable variable providing independent,
#   uncoordinated, *asynchronous* change of individual values. Best used when
#   the value will undergo frequent, complex updates. Suitable when the result
#   of an update does not need to be known immediately.
# * *{Concurrent::Atom}:* Shared, mutable variable providing independent,
#   uncoordinated, *synchronous* change of individual values. Best used when
#   the value will undergo frequent reads but only occasional, though complex,
#   updates. Suitable when the result of an update must be known immediately.
# * *{Concurrent::AtomicReference}:* A simple object reference that can be updated
#   atomically. Updates are synchronous but fast. Best used when updates a
#   simple set operations. Not suitable when updates are complex.
#   {Concurrent::AtomicBoolean} and {Concurrent::AtomicFixnum} are similar
#   but optimized for the given data type.
# * *{Concurrent::Exchanger}:* Shared, stateless synchronization point. Used
#   when two or more threads need to exchange data. The threads will pair then
#   block on each other until the exchange is complete.
# * *{Concurrent::MVar}:* Shared synchronization point. Used when one thread
#   must give a value to another, which must take the value. The threads will
#   block on each other until the exchange is complete.
# * *{Concurrent::ThreadLocalVar}:* Shared, mutable, isolated variable which
#   holds a different value for each thread which has access. Often used as
#   an instance variable in objects which must maintain different state
#   for different threads.
# * *{Concurrent::TVar}:* Shared, mutable variables which provide
#   *coordinated*, *synchronous*, change of *many* stated. Used when multiple
#   value must change together, in an all-or-nothing transaction.
#
# @see http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/atomic/AtomicReference.html
# @see http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/atomic/package-summary.html
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic/atomic_reference.rb#126
class Concurrent::AtomicReference < ::Concurrent::MutexAtomicReference
  # @return [String] Short string representation.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic/atomic_reference.rb#129
  def inspect; end

  # @return [String] Short string representation.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic/atomic_reference.rb#129
  def to_s; end
end

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic/atomic_reference.rb#18
Concurrent::AtomicReferenceImplementation = Concurrent::MutexAtomicReference

# A thread pool that dynamically grows and shrinks to fit the current workload.
# New threads are created as needed, existing threads are reused, and threads
# that remain idle for too long are killed and removed from the pool. These
# pools are particularly suited to applications that perform a high volume of
# short-lived tasks.
#
# On creation a `CachedThreadPool` has zero running threads. New threads are
# created on the pool as new operations are `#post`. The size of the pool
# will grow until `#max_length` threads are in the pool or until the number
# of threads exceeds the number of running and pending operations. When a new
# operation is post to the pool the first available idle thread will be tasked
# with the new operation.
#
# Should a thread crash for any reason the thread will immediately be removed
# from the pool. Similarly, threads which remain idle for an extended period
# of time will be killed and reclaimed. Thus these thread pools are very
# efficient at reclaiming unused resources.
#
# The API and behavior of this class are based on Java's `CachedThreadPool`
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/cached_thread_pool.rb#27
class Concurrent::CachedThreadPool < ::Concurrent::ThreadPoolExecutor
  # Create a new thread pool.
  #
  # @option opts
  # @param opts [Hash] the options defining pool behavior.
  # @raise [ArgumentError] if `fallback_policy` is not a known policy
  # @return [CachedThreadPool] a new instance of CachedThreadPool
  # @see http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Executors.html#newCachedThreadPool--
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/cached_thread_pool.rb#39
  def initialize(opts = T.unsafe(nil)); end

  private

  # Create a new thread pool.
  #
  # @option opts
  # @param opts [Hash] the options defining pool behavior.
  # @raise [ArgumentError] if `fallback_policy` is not a known policy
  # @see http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Executors.html#newCachedThreadPool--
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/cached_thread_pool.rb#51
  def ns_initialize(opts); end
end

# Raised when an asynchronous operation is cancelled before execution.
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/errors.rb#9
class Concurrent::CancelledOperationError < ::Concurrent::Error; end

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb#4
module Concurrent::Collection; end

# A thread safe observer set implemented using copy-on-read approach:
# observers are added and removed from a thread safe collection; every time
# a notification is required the internal data structure is copied to
# prevent concurrency issues
#
# @api private
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/copy_on_notify_observer_set.rb#12
class Concurrent::Collection::CopyOnNotifyObserverSet < ::Concurrent::Synchronization::LockableObject
  # @api private
  # @return [CopyOnNotifyObserverSet] a new instance of CopyOnNotifyObserverSet
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/copy_on_notify_observer_set.rb#14
  def initialize; end

  # @api private
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/copy_on_notify_observer_set.rb#20
  def add_observer(observer = T.unsafe(nil), func = T.unsafe(nil), &block); end

  # @api private
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/copy_on_notify_observer_set.rb#55
  def count_observers; end

  # @api private
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/copy_on_notify_observer_set.rb#39
  def delete_observer(observer); end

  # @api private
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/copy_on_notify_observer_set.rb#47
  def delete_observers; end

  # Notifies all registered observers with optional args and deletes them.
  #
  # @api private
  # @param args [Object] arguments to be passed to each observer
  # @return [CopyOnWriteObserverSet] self
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/copy_on_notify_observer_set.rb#72
  def notify_and_delete_observers(*args, &block); end

  # Notifies all registered observers with optional args
  #
  # @api private
  # @param args [Object] arguments to be passed to each observer
  # @return [CopyOnWriteObserverSet] self
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/copy_on_notify_observer_set.rb#62
  def notify_observers(*args, &block); end

  protected

  # @api private
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/copy_on_notify_observer_set.rb#80
  def ns_initialize; end

  private

  # @api private
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/copy_on_notify_observer_set.rb#86
  def duplicate_and_clear_observers; end

  # @api private
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/copy_on_notify_observer_set.rb#94
  def duplicate_observers; end

  # @api private
  # @raise [ArgumentError]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/copy_on_notify_observer_set.rb#98
  def notify_to(observers, *args); end
end

# A thread safe observer set implemented using copy-on-write approach:
# every time an observer is added or removed the whole internal data structure is
# duplicated and replaced with a new one.
#
# @api private
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb#11
class Concurrent::Collection::CopyOnWriteObserverSet < ::Concurrent::Synchronization::LockableObject
  # @api private
  # @return [CopyOnWriteObserverSet] a new instance of CopyOnWriteObserverSet
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb#13
  def initialize; end

  # @api private
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb#19
  def add_observer(observer = T.unsafe(nil), func = T.unsafe(nil), &block); end

  # @api private
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb#56
  def count_observers; end

  # @api private
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb#40
  def delete_observer(observer); end

  # @api private
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb#50
  def delete_observers; end

  # Notifies all registered observers with optional args and deletes them.
  #
  # @api private
  # @param args [Object] arguments to be passed to each observer
  # @return [CopyOnWriteObserverSet] self
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb#72
  def notify_and_delete_observers(*args, &block); end

  # Notifies all registered observers with optional args
  #
  # @api private
  # @param args [Object] arguments to be passed to each observer
  # @return [CopyOnWriteObserverSet] self
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb#63
  def notify_observers(*args, &block); end

  protected

  # @api private
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb#80
  def ns_initialize; end

  private

  # @api private
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb#102
  def clear_observers_and_return_old; end

  # @api private
  # @raise [ArgumentError]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb#86
  def notify_to(observers, *args); end

  # @api private
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb#94
  def observers; end

  # @api private
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/copy_on_write_observer_set.rb#98
  def observers=(new_set); end
end

# A queue collection in which the elements are sorted based on their
# comparison (spaceship) operator `<=>`. Items are added to the queue
# at a position relative to their priority. On removal the element
# with the "highest" priority is removed. By default the sort order is
# from highest to lowest, but a lowest-to-highest sort order can be
# set on construction.
#
# The API is based on the `Queue` class from the Ruby standard library.
#
# The pure Ruby implementation, `RubyNonConcurrentPriorityQueue` uses a heap algorithm
# stored in an array. The algorithm is based on the work of Robert Sedgewick
# and Kevin Wayne.
#
# The JRuby native implementation is a thin wrapper around the standard
# library `java.util.NonConcurrentPriorityQueue`.
#
# When running under JRuby the class `NonConcurrentPriorityQueue` extends `JavaNonConcurrentPriorityQueue`.
# When running under all other interpreters it extends `RubyNonConcurrentPriorityQueue`.
#
# @note This implementation is *not* thread safe.
# @see http://en.wikipedia.org/wiki/Priority_queue
# @see http://ruby-doc.org/stdlib-2.0.0/libdoc/thread/rdoc/Queue.html
# @see http://algs4.cs.princeton.edu/24pq/index.php#2.6
# @see http://algs4.cs.princeton.edu/24pq/MaxPQ.java.html
# @see http://docs.oracle.com/javase/7/docs/api/java/util/PriorityQueue.html
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/non_concurrent_priority_queue.rb#50
class Concurrent::Collection::NonConcurrentPriorityQueue < ::Concurrent::Collection::RubyNonConcurrentPriorityQueue
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#78
  def <<(item); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#65
  def deq; end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#78
  def enq(item); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#48
  def has_priority?(item); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#65
  def shift; end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#54
  def size; end
end

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/non_concurrent_priority_queue.rb#10
Concurrent::Collection::NonConcurrentPriorityQueueImplementation = Concurrent::Collection::RubyNonConcurrentPriorityQueue

# A queue collection in which the elements are sorted based on their
# comparison (spaceship) operator `<=>`. Items are added to the queue
# at a position relative to their priority. On removal the element
# with the "highest" priority is removed. By default the sort order is
# from highest to lowest, but a lowest-to-highest sort order can be
# set on construction.
#
# The API is based on the `Queue` class from the Ruby standard library.
#
# The pure Ruby implementation, `RubyNonConcurrentPriorityQueue` uses a heap algorithm
# stored in an array. The algorithm is based on the work of Robert Sedgewick
# and Kevin Wayne.
#
# The JRuby native implementation is a thin wrapper around the standard
# library `java.util.NonConcurrentPriorityQueue`.
#
# When running under JRuby the class `NonConcurrentPriorityQueue` extends `JavaNonConcurrentPriorityQueue`.
# When running under all other interpreters it extends `RubyNonConcurrentPriorityQueue`.
#
# @note This implementation is *not* thread safe.
# @see http://en.wikipedia.org/wiki/Priority_queue
# @see http://ruby-doc.org/stdlib-2.0.0/libdoc/thread/rdoc/Queue.html
# @see http://algs4.cs.princeton.edu/24pq/index.php#2.6
# @see http://algs4.cs.princeton.edu/24pq/MaxPQ.java.html
# @see http://docs.oracle.com/javase/7/docs/api/java/util/PriorityQueue.html
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#8
class Concurrent::Collection::RubyNonConcurrentPriorityQueue
  # Create a new priority queue with no items.
  #
  # @option opts
  # @param opts [Hash] the options for creating the queue
  # @return [RubyNonConcurrentPriorityQueue] a new instance of RubyNonConcurrentPriorityQueue
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#11
  def initialize(opts = T.unsafe(nil)); end

  # Inserts the specified element into this priority queue.
  #
  # @param item [Object] the item to insert onto the queue
  # @raise [ArgumentError]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#78
  def <<(item); end

  # Removes all of the elements from this priority queue.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#18
  def clear; end

  # Deletes all items from `self` that are equal to `item`.
  #
  # @param item [Object] the item to be removed from the queue
  # @return [Object] true if the item is found else false
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#25
  def delete(item); end

  # Retrieves and removes the head of this queue, or returns `nil` if this
  # queue is empty.
  #
  # @return [Object] the head of the queue or `nil` when empty
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#65
  def deq; end

  # Returns `true` if `self` contains no elements.
  #
  # @return [Boolean] true if there are no items in the queue else false
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#43
  def empty?; end

  # Inserts the specified element into this priority queue.
  #
  # @param item [Object] the item to insert onto the queue
  # @raise [ArgumentError]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#78
  def enq(item); end

  # Returns `true` if the given item is present in `self` (that is, if any
  # element == `item`), otherwise returns false.
  #
  # @param item [Object] the item to search for
  # @return [Boolean] true if the item is found else false
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#48
  def has_priority?(item); end

  # Returns `true` if the given item is present in `self` (that is, if any
  # element == `item`), otherwise returns false.
  #
  # @param item [Object] the item to search for
  # @return [Boolean] true if the item is found else false
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#48
  def include?(item); end

  # The current length of the queue.
  #
  # @return [Fixnum] the number of items in the queue
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#54
  def length; end

  # Retrieves, but does not remove, the head of this queue, or returns `nil`
  # if this queue is empty.
  #
  # @return [Object] the head of the queue or `nil` when empty
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#60
  def peek; end

  # Retrieves and removes the head of this queue, or returns `nil` if this
  # queue is empty.
  #
  # @return [Object] the head of the queue or `nil` when empty
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#65
  def pop; end

  # Inserts the specified element into this priority queue.
  #
  # @param item [Object] the item to insert onto the queue
  # @raise [ArgumentError]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#78
  def push(item); end

  # Retrieves and removes the head of this queue, or returns `nil` if this
  # queue is empty.
  #
  # @return [Object] the head of the queue or `nil` when empty
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#65
  def shift; end

  # The current length of the queue.
  #
  # @return [Fixnum] the number of items in the queue
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#54
  def size; end

  private

  # Are the items at the given indexes ordered based on the priority
  # order specified at construction?
  #
  # @param x [Integer] the first index from which to retrieve a comparable value
  # @param y [Integer] the second index from which to retrieve a comparable value
  # @return [Boolean] true if the two elements are in the correct priority order
  #   else false
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#119
  def ordered?(x, y); end

  # Percolate down to maintain heap invariant.
  #
  # @param k [Integer] the index at which to start the percolation
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#128
  def sink(k); end

  # Exchange the values at the given indexes within the internal array.
  #
  # @param x [Integer] the first index to swap
  # @param y [Integer] the second index to swap
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#103
  def swap(x, y); end

  # Percolate up to maintain heap invariant.
  #
  # @param k [Integer] the index at which to start the percolation
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#147
  def swim(k); end

  class << self
    # @!macro priority_queue_method_from_list
    #
    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/collection/ruby_non_concurrent_priority_queue.rb#89
    def from_list(list, opts = T.unsafe(nil)); end
  end
end

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/dereferenceable.rb#2
module Concurrent::Concern; end

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/deprecation.rb#8
module Concurrent::Concern::Deprecation
  include ::Logger::Severity
  include ::Concurrent::Concern::Logging
  extend ::Logger::Severity
  extend ::Concurrent::Concern::Logging
  extend ::Concurrent::Concern::Deprecation

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/deprecation.rb#12
  def deprecated(message, strip = T.unsafe(nil)); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/deprecation.rb#27
  def deprecated_method(old_name, new_name); end
end

# Object references in Ruby are mutable. This can lead to serious problems when
# the `#value` of a concurrent object is a mutable reference. Which is always the
# case unless the value is a `Fixnum`, `Symbol`, or similar "primitive" data type.
# Most classes in this library that expose a `#value` getter method do so using the
# `Dereferenceable` mixin module.
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/dereferenceable.rb#11
module Concurrent::Concern::Dereferenceable
  # Return the value this object represents after applying the options specified
  # by the `#set_deref_options` method.
  #
  # @return [Object] the current value of the object
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/dereferenceable.rb#21
  def deref; end

  # Return the value this object represents after applying the options specified
  # by the `#set_deref_options` method.
  #
  # @return [Object] the current value of the object
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/dereferenceable.rb#21
  def value; end

  protected

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/dereferenceable.rb#63
  def apply_deref_options(value); end

  # Set the options which define the operations #value performs before
  # returning data to the caller (dereferencing).
  #
  # @note Most classes that include this module will call `#set_deref_options`
  #   from within the constructor, thus allowing these options to be set at
  #   object creation.
  # @option opts
  # @option opts
  # @option opts
  # @param opts [Hash] the options defining dereference behavior.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/dereferenceable.rb#54
  def ns_set_deref_options(opts); end

  # Set the options which define the operations #value performs before
  # returning data to the caller (dereferencing).
  #
  # @note Most classes that include this module will call `#set_deref_options`
  #   from within the constructor, thus allowing these options to be set at
  #   object creation.
  # @option opts
  # @option opts
  # @option opts
  # @param opts [Hash] the options defining dereference behavior.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/dereferenceable.rb#48
  def set_deref_options(opts = T.unsafe(nil)); end

  # Set the internal value of this object
  #
  # @param value [Object] the new value
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/dereferenceable.rb#31
  def value=(value); end
end

# Include where logging is needed
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/logging.rb#10
module Concurrent::Concern::Logging
  include ::Logger::Severity

  # Logs through {Concurrent.global_logger}, it can be overridden by setting @logger
  #
  # @param level [Integer] one of Logger::Severity constants
  # @param progname [String] e.g. a path of an Actor
  # @param message [String, nil] when nil block is used to generate the message
  # @yieldreturn [String] a message
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/logging.rb#18
  def log(level, progname, message = T.unsafe(nil), &block); end
end

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/obligation.rb#10
module Concurrent::Concern::Obligation
  include ::Concurrent::Concern::Dereferenceable

  # Has the obligation completed processing?
  #
  # @return [Boolean]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/obligation.rb#49
  def complete?; end

  # @example allows Obligation to be risen
  #   rejected_ivar = Ivar.new.fail
  #   raise rejected_ivar
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/obligation.rb#126
  def exception(*args); end

  # Has the obligation been fulfilled?
  #
  # @return [Boolean]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/obligation.rb#20
  def fulfilled?; end

  # Is the obligation still awaiting completion of processing?
  #
  # @return [Boolean]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/obligation.rb#56
  def incomplete?; end

  # Wait until obligation is complete or the timeout is reached. Will re-raise
  # any exceptions raised during processing (but will not raise an exception
  # on timeout).
  #
  # @param timeout [Numeric] the maximum time in seconds to wait.
  # @raise [Exception] raises the reason when rejected
  # @return [Obligation] self
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/obligation.rb#86
  def no_error!(timeout = T.unsafe(nil)); end

  # Is obligation completion still pending?
  #
  # @return [Boolean]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/obligation.rb#35
  def pending?; end

  # Has the obligation been fulfilled?
  #
  # @return [Boolean]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/obligation.rb#20
  def realized?; end

  # If an exception was raised during processing this will return the
  # exception object. Will return `nil` when the state is pending or if
  # the obligation has been successfully fulfilled.
  #
  # @return [Exception] the exception raised during processing or `nil`
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/obligation.rb#119
  def reason; end

  # Has the obligation been rejected?
  #
  # @return [Boolean]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/obligation.rb#28
  def rejected?; end

  # The current state of the obligation.
  #
  # @return [Symbol] the current state
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/obligation.rb#110
  def state; end

  # Is the obligation still unscheduled?
  #
  # @return [Boolean]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/obligation.rb#42
  def unscheduled?; end

  # The current value of the obligation. Will be `nil` while the state is
  # pending or the operation has been rejected.
  #
  # @param timeout [Numeric] the maximum time in seconds to wait.
  # @return [Object] see Dereferenceable#deref
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/obligation.rb#65
  def value(timeout = T.unsafe(nil)); end

  # The current value of the obligation. Will be `nil` while the state is
  # pending or the operation has been rejected. Will re-raise any exceptions
  # raised during processing (but will not raise an exception on timeout).
  #
  # @param timeout [Numeric] the maximum time in seconds to wait.
  # @raise [Exception] raises the reason when rejected
  # @return [Object] see Dereferenceable#deref
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/obligation.rb#98
  def value!(timeout = T.unsafe(nil)); end

  # Wait until obligation is complete or the timeout has been reached.
  #
  # @param timeout [Numeric] the maximum time in seconds to wait.
  # @return [Obligation] self
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/obligation.rb#74
  def wait(timeout = T.unsafe(nil)); end

  # Wait until obligation is complete or the timeout is reached. Will re-raise
  # any exceptions raised during processing (but will not raise an exception
  # on timeout).
  #
  # @param timeout [Numeric] the maximum time in seconds to wait.
  # @raise [Exception] raises the reason when rejected
  # @return [Obligation] self
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/obligation.rb#86
  def wait!(timeout = T.unsafe(nil)); end

  protected

  # Atomic compare and set operation
  # State is set to `next_state` only if `current state == expected_current`.
  #
  # @param next_state [Symbol]
  # @param expected_current [Symbol]
  # @return [Boolean] true is state is changed, false otherwise
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/obligation.rb#174
  def compare_and_set_state(next_state, *expected_current); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/obligation.rb#145
  def event; end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/obligation.rb#134
  def get_arguments_from(opts = T.unsafe(nil)); end

  # Executes the block within mutex if current state is included in expected_states
  #
  # @return block value if executed, false otherwise
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/obligation.rb#190
  def if_state(*expected_states); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/obligation.rb#139
  def init_obligation; end

  # Am I in the current state?
  #
  # @param expected [Symbol] The state to check against
  # @return [Boolean] true if in the expected state else false
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/obligation.rb#210
  def ns_check_state?(expected); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/obligation.rb#215
  def ns_set_state(value); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/obligation.rb#150
  def set_state(success, value, reason); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/obligation.rb#161
  def state=(value); end
end

# The [observer pattern](http://en.wikipedia.org/wiki/Observer_pattern) is one
# of the most useful design patterns.
#
# The workflow is very simple:
# - an `observer` can register itself to a `subject` via a callback
# - many `observers` can be registered to the same `subject`
# - the `subject` notifies all registered observers when its status changes
# - an `observer` can deregister itself when is no more interested to receive
#     event notifications
#
# In a single threaded environment the whole pattern is very easy: the
# `subject` can use a simple data structure to manage all its subscribed
# `observer`s and every `observer` can react directly to every event without
# caring about synchronization.
#
# In a multi threaded environment things are more complex. The `subject` must
# synchronize the access to its data structure and to do so currently we're
# using two specialized ObserverSet: {Concurrent::Concern::CopyOnWriteObserverSet}
# and {Concurrent::Concern::CopyOnNotifyObserverSet}.
#
# When implementing and `observer` there's a very important rule to remember:
# **there are no guarantees about the thread that will execute the callback**
#
# Let's take this example
# ```
# class Observer
#   def initialize
#     @count = 0
#   end
#
#   def update
#     @count += 1
#   end
# end
#
# obs = Observer.new
# [obj1, obj2, obj3, obj4].each { |o| o.add_observer(obs) }
# # execute [obj1, obj2, obj3, obj4]
# ```
#
# `obs` is wrong because the variable `@count` can be accessed by different
# threads at the same time, so it should be synchronized (using either a Mutex
# or an AtomicFixum)
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/observable.rb#50
module Concurrent::Concern::Observable
  # Adds an observer to this set. If a block is passed, the observer will be
  # created by this method and no other params should be passed.
  #
  # @param observer [Object] the observer to add
  # @param func [Symbol] the function to call on the observer during notification.
  #   Default is :update
  # @return [Object] the added observer
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/observable.rb#61
  def add_observer(observer = T.unsafe(nil), func = T.unsafe(nil), &block); end

  # Return the number of observers associated with this object.
  #
  # @return [Integer] the observers count
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/observable.rb#101
  def count_observers; end

  # Remove `observer` as an observer on this object so that it will no
  # longer receive notifications.
  #
  # @param observer [Object] the observer to remove
  # @return [Object] the deleted observer
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/observable.rb#82
  def delete_observer(observer); end

  # Remove all observers associated with this object.
  #
  # @return [Observable] self
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/observable.rb#91
  def delete_observers; end

  # As `#add_observer` but can be used for chaining.
  #
  # @param observer [Object] the observer to add
  # @param func [Symbol] the function to call on the observer during notification.
  # @return [Observable] self
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/observable.rb#70
  def with_observer(observer = T.unsafe(nil), func = T.unsafe(nil), &block); end

  protected

  # Returns the value of attribute observers.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/observable.rb#107
  def observers; end

  # Sets the attribute observers
  #
  # @param value the value to set the attribute observers to.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/observable.rb#107
  def observers=(_arg0); end
end

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/errors.rb#70
class Concurrent::ConcurrentUpdateError < ::ThreadError; end

# frozen pre-allocated backtrace to speed ConcurrentUpdateError
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/errors.rb#72
Concurrent::ConcurrentUpdateError::CONC_UP_ERR_BACKTRACE = T.let(T.unsafe(nil), Array)

# Raised when errors occur during configuration.
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/errors.rb#6
class Concurrent::ConfigurationError < ::Concurrent::Error; end

# Lazy evaluation of a block yielding an immutable result. Useful for
# expensive operations that may never be needed. It may be non-blocking,
# supports the `Concern::Obligation` interface, and accepts the injection of
# custom executor upon which to execute the block. Processing of
# block will be deferred until the first time `#value` is called.
# At that time the caller can choose to return immediately and let
# the block execute asynchronously, block indefinitely, or block
# with a timeout.
#
# When a `Delay` is created its state is set to `pending`. The value and
# reason are both `nil`. The first time the `#value` method is called the
# enclosed opration will be run and the calling thread will block. Other
# threads attempting to call `#value` will block as well. Once the operation
# is complete the *value* will be set to the result of the operation or the
# *reason* will be set to the raised exception, as appropriate. All threads
# blocked on `#value` will return. Subsequent calls to `#value` will immediately
# return the cached value. The operation will only be run once. This means that
# any side effects created by the operation will only happen once as well.
#
# `Delay` includes the `Concurrent::Concern::Dereferenceable` mixin to support thread
# safety of the reference returned by `#value`.
#
# @note The default behavior of `Delay` is to block indefinitely when
#   calling either `value` or `wait`, executing the delayed operation on
#   the current thread. This makes the `timeout` value completely
#   irrelevant. To enable non-blocking behavior, use the `executor`
#   constructor option. This will cause the delayed operation to be
#   execute on the given executor, allowing the call to timeout.
# @see Concurrent::Concern::Dereferenceable
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/delay.rb#44
class Concurrent::Delay < ::Concurrent::Synchronization::LockableObject
  include ::Concurrent::Concern::Dereferenceable
  include ::Concurrent::Concern::Obligation

  # Create a new `Delay` in the `:pending` state.
  #
  # @raise [ArgumentError] if no block is given
  # @return [Delay] a new instance of Delay
  # @yield the delayed operation to perform
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/delay.rb#62
  def initialize(opts = T.unsafe(nil), &block); end

  # Reconfigures the block returning the value if still `#incomplete?`
  #
  # @return [true, false] if success
  # @yield the delayed operation to perform
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/delay.rb#146
  def reconfigure(&block); end

  # Return the value this object represents after applying the options
  # specified by the `#set_deref_options` method. If the delayed operation
  # raised an exception this method will return nil. The exception object
  # can be accessed via the `#reason` method.
  #
  # @note The default behavior of `Delay` is to block indefinitely when
  #   calling either `value` or `wait`, executing the delayed operation on
  #   the current thread. This makes the `timeout` value completely
  #   irrelevant. To enable non-blocking behavior, use the `executor`
  #   constructor option. This will cause the delayed operation to be
  #   execute on the given executor, allowing the call to timeout.
  # @param timeout [Numeric] the maximum number of seconds to wait
  # @return [Object] the current value of the object
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/delay.rb#77
  def value(timeout = T.unsafe(nil)); end

  # Return the value this object represents after applying the options
  # specified by the `#set_deref_options` method. If the delayed operation
  # raised an exception, this method will raise that exception (even when)
  # the operation has already been executed).
  #
  # @note The default behavior of `Delay` is to block indefinitely when
  #   calling either `value` or `wait`, executing the delayed operation on
  #   the current thread. This makes the `timeout` value completely
  #   irrelevant. To enable non-blocking behavior, use the `executor`
  #   constructor option. This will cause the delayed operation to be
  #   execute on the given executor, allowing the call to timeout.
  # @param timeout [Numeric] the maximum number of seconds to wait
  # @raise [Exception] when `#rejected?` raises `#reason`
  # @return [Object] the current value of the object
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/delay.rb#113
  def value!(timeout = T.unsafe(nil)); end

  # Return the value this object represents after applying the options
  # specified by the `#set_deref_options` method.
  #
  # @note The default behavior of `Delay` is to block indefinitely when
  #   calling either `value` or `wait`, executing the delayed operation on
  #   the current thread. This makes the `timeout` value completely
  #   irrelevant. To enable non-blocking behavior, use the `executor`
  #   constructor option. This will cause the delayed operation to be
  #   execute on the given executor, allowing the call to timeout.
  # @param timeout [Integer] (nil) the maximum number of seconds to wait for
  #   the value to be computed. When `nil` the caller will block indefinitely.
  # @return [Object] self
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/delay.rb#132
  def wait(timeout = T.unsafe(nil)); end

  protected

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/delay.rb#160
  def ns_initialize(opts, &block); end

  private

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/delay.rb#173
  def execute_task_once; end
end

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/errors.rb#3
class Concurrent::Error < ::StandardError; end

# Old school kernel-style event reminiscent of Win32 programming in C++.
#
# When an `Event` is created it is in the `unset` state. Threads can choose to
# `#wait` on the event, blocking until released by another thread. When one
# thread wants to alert all blocking threads it calls the `#set` method which
# will then wake up all listeners. Once an `Event` has been set it remains set.
# New threads calling `#wait` will return immediately. An `Event` may be
# `#reset` at any time once it has been set.
#
# @example
#   event = Concurrent::Event.new
#
#   t1 = Thread.new do
#   puts "t1 is waiting"
#   event.wait(1)
#   puts "event occurred"
#   end
#
#   t2 = Thread.new do
#   puts "t2 calling set"
#   event.set
#   end
#
#   [t1, t2].each(&:join)
#
#   # prints:
#   # t1 is waiting
#   # t2 calling set
#   # event occurred
# @see http://msdn.microsoft.com/en-us/library/windows/desktop/ms682655.aspx
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic/event.rb#36
class Concurrent::Event < ::Concurrent::Synchronization::LockableObject
  # Creates a new `Event` in the unset state. Threads calling `#wait` on the
  # `Event` will block.
  #
  # @return [Event] a new instance of Event
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic/event.rb#40
  def initialize; end

  # Reset a previously set event back to the `unset` state.
  # Has no effect if the `Event` has not yet been set.
  #
  # @return [Boolean] should always return `true`
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic/event.rb#68
  def reset; end

  # Trigger the event, setting the state to `set` and releasing all threads
  # waiting on the event. Has no effect if the `Event` has already been set.
  #
  # @return [Boolean] should always return `true`
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic/event.rb#56
  def set; end

  # Is the object in the set state?
  #
  # @return [Boolean] indicating whether or not the `Event` has been set
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic/event.rb#48
  def set?; end

  # @return [Boolean]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic/event.rb#60
  def try?; end

  # Wait a given number of seconds for the `Event` to be set by another
  # thread. Will wait forever when no `timeout` value is given. Returns
  # immediately if the `Event` has already been set.
  #
  # @return [Boolean] true if the `Event` was set before timeout else false
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic/event.rb#83
  def wait(timeout = T.unsafe(nil)); end

  protected

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic/event.rb#104
  def ns_initialize; end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic/event.rb#96
  def ns_set; end
end

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/executor_service.rb#157
module Concurrent::ExecutorService
  include ::Logger::Severity
  include ::Concurrent::Concern::Logging

  # Submit a task to the executor for asynchronous processing.
  #
  # @param task [Proc] the asynchronous task to perform
  # @return [self] returns itself
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/executor_service.rb#166
  def <<(task); end

  # Does the task queue have a maximum size?
  #
  # @note Always returns `false`
  # @return [Boolean] True if the task queue has a maximum size else false.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/executor_service.rb#174
  def can_overflow?; end

  # Submit a task to the executor for asynchronous processing.
  #
  # @param args [Array] zero or more arguments to be passed to the task
  # @raise [ArgumentError] if no task is given
  # @return [Boolean] `true` if the task is queued, `false` if the executor
  #   is not running
  # @yield the asynchronous task to perform
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/executor_service.rb#161
  def post(*args, &task); end

  # Does this executor guarantee serialization of its operations?
  #
  # @note Always returns `false`
  # @return [Boolean] True if the executor guarantees that all operations
  #   will be post in the order they are received and no two operations may
  #   occur simultaneously. Else false.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/executor_service.rb#181
  def serialized?; end
end

# A thread pool that reuses a fixed number of threads operating off an unbounded queue.
# At any point, at most `num_threads` will be active processing tasks. When all threads are busy new
# tasks `#post` to the thread pool are enqueued until a thread becomes available.
# Should a thread crash for any reason the thread will immediately be removed
# from the pool and replaced.
#
# The API and behavior of this class are based on Java's `FixedThreadPool`
#
# **Thread Pool Options**
#
# Thread pools support several configuration options:
#
# * `idletime`: The number of seconds that a thread may be idle before being reclaimed.
# * `name`: The name of the executor (optional). Printed in the executor's `#to_s` output and
#   a `<name>-worker-<id>` name is given to its threads if supported by used Ruby
#   implementation. `<id>` is uniq for each thread.
# * `max_queue`: The maximum number of tasks that may be waiting in the work queue at
#   any one time. When the queue size reaches `max_queue` and no new threads can be created,
#   subsequent tasks will be rejected in accordance with the configured `fallback_policy`.
# * `auto_terminate`: When true (default), the threads started will be marked as daemon.
# * `fallback_policy`: The policy defining how rejected tasks are handled.
#
# Three fallback policies are supported:
#
# * `:abort`: Raise a `RejectedExecutionError` exception and discard the task.
# * `:discard`: Discard the task and return false.
# * `:caller_runs`: Execute the task on the calling thread.
#
# **Shutting Down Thread Pools**
#
# Killing a thread pool while tasks are still being processed, either by calling
# the `#kill` method or at application exit, will have unpredictable results. There
# is no way for the thread pool to know what resources are being used by the
# in-progress tasks. When those tasks are killed the impact on those resources
# cannot be predicted. The *best* practice is to explicitly shutdown all thread
# pools using the provided methods:
#
# * Call `#shutdown` to initiate an orderly termination of all in-progress tasks
# * Call `#wait_for_termination` with an appropriate timeout interval an allow
#   the orderly shutdown to complete
# * Call `#kill` *only when* the thread pool fails to shutdown in the allotted time
#
# On some runtime platforms (most notably the JVM) the application will not
# exit until all thread pools have been shutdown. To prevent applications from
# "hanging" on exit, all threads can be marked as daemon according to the
# `:auto_terminate` option.
#
# ```ruby
# pool1 = Concurrent::FixedThreadPool.new(5) # threads will be marked as daemon
# pool2 = Concurrent::FixedThreadPool.new(5, auto_terminate: false) # mark threads as non-daemon
# ```
#
# @note Failure to properly shutdown a thread pool can lead to unpredictable results.
#   Please read *Shutting Down Thread Pools* for more information.
# @see http://docs.oracle.com/javase/tutorial/essential/concurrency/pools.html Java Tutorials: Thread Pools
# @see http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/Executors.html Java Executors class
# @see http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ExecutorService.html Java ExecutorService interface
# @see https://docs.oracle.com/javase/8/docs/api/java/lang/Thread.html#setDaemon-boolean-
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/fixed_thread_pool.rb#201
class Concurrent::FixedThreadPool < ::Concurrent::ThreadPoolExecutor
  # Create a new thread pool.
  #
  # @option opts
  # @param num_threads [Integer] the number of threads to allocate
  # @param opts [Hash] the options defining pool behavior.
  # @raise [ArgumentError] if `num_threads` is less than or equal to zero
  # @raise [ArgumentError] if `fallback_policy` is not a known policy
  # @return [FixedThreadPool] a new instance of FixedThreadPool
  # @see http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Executors.html#newFixedThreadPool-int-
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/fixed_thread_pool.rb#215
  def initialize(num_threads, opts = T.unsafe(nil)); end
end

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/configuration.rb#18
Concurrent::GLOBAL_FAST_EXECUTOR = T.let(T.unsafe(nil), Concurrent::Delay)

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/configuration.rb#30
Concurrent::GLOBAL_IMMEDIATE_EXECUTOR = T.let(T.unsafe(nil), Concurrent::ImmediateExecutor)

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/configuration.rb#22
Concurrent::GLOBAL_IO_EXECUTOR = T.let(T.unsafe(nil), Concurrent::Delay)

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/logging.rb#106
Concurrent::GLOBAL_LOGGER = T.let(T.unsafe(nil), Concurrent::AtomicReference)

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/configuration.rb#26
Concurrent::GLOBAL_TIMER_SET = T.let(T.unsafe(nil), Concurrent::Delay)

# An `IVar` is like a future that you can assign. As a future is a value that
# is being computed that you can wait on, an `IVar` is a value that is waiting
# to be assigned, that you can wait on. `IVars` are single assignment and
# deterministic.
#
# Then, express futures as an asynchronous computation that assigns an `IVar`.
# The `IVar` becomes the primitive on which [futures](Future) and
# [dataflow](Dataflow) are built.
#
# An `IVar` is a single-element container that is normally created empty, and
# can only be set once. The I in `IVar` stands for immutable. Reading an
# `IVar` normally blocks until it is set. It is safe to set and read an `IVar`
# from different threads.
#
# If you want to have some parallel task set the value in an `IVar`, you want
# a `Future`. If you want to create a graph of parallel tasks all executed
# when the values they depend on are ready you want `dataflow`. `IVar` is
# generally a low-level primitive.
#
# ## Examples
#
# Create, set and get an `IVar`
#
# ```ruby
# ivar = Concurrent::IVar.new
# ivar.set 14
# ivar.value #=> 14
# ivar.set 2 # would now be an error
# ```
#
# ## See Also
#
# 1. For the theory: Arvind, R. Nikhil, and K. Pingali.
#    [I-Structures: Data structures for parallel computing](http://dl.acm.org/citation.cfm?id=69562).
#    In Proceedings of Workshop on Graph Reduction, 1986.
# 2. For recent application:
#    [DataDrivenFuture in Habanero Java from Rice](http://www.cs.rice.edu/~vs3/hjlib/doc/edu/rice/hj/api/HjDataDrivenFuture.html).
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/ivar.rb#48
class Concurrent::IVar < ::Concurrent::Synchronization::LockableObject
  include ::Concurrent::Concern::Dereferenceable
  include ::Concurrent::Concern::Obligation
  include ::Concurrent::Concern::Observable

  # Create a new `IVar` in the `:pending` state with the (optional) initial value.
  #
  # @option opts
  # @option opts
  # @option opts
  # @param value [Object] the initial value
  # @param opts [Hash] the options to create a message with
  # @return [IVar] a new instance of IVar
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/ivar.rb#62
  def initialize(value = T.unsafe(nil), opts = T.unsafe(nil), &block); end

  # Add an observer on this object that will receive notification on update.
  #
  # Upon completion the `IVar` will notify all observers in a thread-safe way.
  # The `func` method of the observer will be called with three arguments: the
  # `Time` at which the `Future` completed the asynchronous operation, the
  # final `value` (or `nil` on rejection), and the final `reason` (or `nil` on
  # fulfillment).
  #
  # @param observer [Object] the object that will be notified of changes
  # @param func [Symbol] symbol naming the method to call when this
  #   `Observable` has changes`
  # @raise [ArgumentError]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/ivar.rb#81
  def add_observer(observer = T.unsafe(nil), func = T.unsafe(nil), &block); end

  # Set the `IVar` to failed due to some error and wake or notify all threads waiting on it.
  #
  # @param reason [Object] for the failure
  # @raise [Concurrent::MultipleAssignmentError] if the `IVar` has already
  #   been set or otherwise completed
  # @return [IVar] self
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/ivar.rb#135
  def fail(reason = T.unsafe(nil)); end

  # Set the `IVar` to a value and wake or notify all threads waiting on it.
  #
  # @param value [Object] the value to store in the `IVar`
  # @raise [ArgumentError] if both a value and a block are given
  # @raise [Concurrent::MultipleAssignmentError] if the `IVar` has already
  #   been set or otherwise completed
  # @return [IVar] self
  # @yield A block operation to use for setting the value
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/ivar.rb#113
  def set(value = T.unsafe(nil)); end

  # Attempt to set the `IVar` with the given value or block. Return a
  # boolean indicating the success or failure of the set operation.
  #
  # @param value [Object] the value to store in the `IVar`
  # @raise [ArgumentError] if both a value and a block are given
  # @raise [Concurrent::MultipleAssignmentError] if the `IVar` has already
  #   been set or otherwise completed
  # @return [Boolean] true if the value was set else false
  # @yield A block operation to use for setting the value
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/ivar.rb#145
  def try_set(value = T.unsafe(nil), &block); end

  protected

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/ivar.rb#202
  def check_for_block_or_value!(block_given, value); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/ivar.rb#177
  def complete(success, value, reason); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/ivar.rb#184
  def complete_without_notification(success, value, reason); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/ivar.rb#190
  def notify_observers(value, reason); end

  # @raise [MultipleAssignmentError]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/ivar.rb#195
  def ns_complete_without_notification(success, value, reason); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/ivar.rb#155
  def ns_initialize(value, opts); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/ivar.rb#168
  def safe_execute(task, args = T.unsafe(nil)); end
end

# Raised when an operation is attempted which is not legal given the
# receiver's current state
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/errors.rb#20
class Concurrent::IllegalOperationError < ::Concurrent::Error; end

# An executor service which runs all operations on the current thread,
# blocking as necessary. Operations are performed in the order they are
# received and no two operations can be performed simultaneously.
#
# This executor service exists mainly for testing an debugging. When used
# it immediately runs every `#post` operation on the current thread, blocking
# that thread until the operation is complete. This can be very beneficial
# during testing because it makes all operations deterministic.
#
# @note Intended for use primarily in testing and debugging.
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/immediate_executor.rb#17
class Concurrent::ImmediateExecutor < ::Concurrent::AbstractExecutorService
  include ::Concurrent::SerialExecutorService

  # Creates a new executor
  #
  # @return [ImmediateExecutor] a new instance of ImmediateExecutor
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/immediate_executor.rb#21
  def initialize; end

  # Submit a task to the executor for asynchronous processing.
  #
  # @param task [Proc] the asynchronous task to perform
  # @return [self] returns itself
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/immediate_executor.rb#34
  def <<(task); end

  # Begin an orderly shutdown. Tasks already in the queue will be executed,
  # but no new tasks will be accepted. Has no additional effect if the
  # thread pool is not running.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/immediate_executor.rb#55
  def kill; end

  # Submit a task to the executor for asynchronous processing.
  #
  # @param args [Array] zero or more arguments to be passed to the task
  # @raise [ArgumentError] if no task is given
  # @return [Boolean] `true` if the task is queued, `false` if the executor
  #   is not running
  # @yield the asynchronous task to perform
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/immediate_executor.rb#26
  def post(*args, &task); end

  # Is the executor running?
  #
  # @return [Boolean] `true` when running, `false` when shutting down or shutdown
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/immediate_executor.rb#40
  def running?; end

  # Begin an orderly shutdown. Tasks already in the queue will be executed,
  # but no new tasks will be accepted. Has no additional effect if the
  # thread pool is not running.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/immediate_executor.rb#55
  def shutdown; end

  # Is the executor shutdown?
  #
  # @return [Boolean] `true` when shutdown, `false` when shutting down or running
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/immediate_executor.rb#50
  def shutdown?; end

  # Is the executor shuttingdown?
  #
  # @return [Boolean] `true` when not running and not shutdown, else `false`
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/immediate_executor.rb#45
  def shuttingdown?; end

  # Block until executor shutdown is complete or until `timeout` seconds have
  # passed.
  #
  # @note Does not initiate shutdown or termination. Either `shutdown` or `kill`
  #   must be called before this method (or on another thread).
  # @param timeout [Integer] the maximum number of seconds to wait for shutdown to complete
  # @return [Boolean] `true` if shutdown complete or false on `timeout`
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/immediate_executor.rb#62
  def wait_for_termination(timeout = T.unsafe(nil)); end
end

# Raised when an attempt is made to violate an immutability guarantee.
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/errors.rb#16
class Concurrent::ImmutabilityError < ::Concurrent::Error; end

# Raised when an object's methods are called when it has not been
# properly initialized.
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/errors.rb#24
class Concurrent::InitializationError < ::Concurrent::Error; end

# Raised when a lifecycle method (such as `stop`) is called in an improper
# sequence or when the object is in an inappropriate state.
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/errors.rb#13
class Concurrent::LifecycleError < ::Concurrent::Error; end

# Raised when an object with a start/stop lifecycle has been started an
# excessive number of times. Often used in conjunction with a restart
# policy or strategy.
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/errors.rb#29
class Concurrent::MaxRestartFrequencyError < ::Concurrent::Error; end

# Raised when an attempt is made to modify an immutable object
# (such as an `IVar`) after its final state has been set.
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/errors.rb#33
class Concurrent::MultipleAssignmentError < ::Concurrent::Error
  # @return [MultipleAssignmentError] a new instance of MultipleAssignmentError
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/errors.rb#36
  def initialize(message = T.unsafe(nil), inspection_data = T.unsafe(nil)); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/errors.rb#41
  def inspect; end

  # Returns the value of attribute inspection_data.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/errors.rb#34
  def inspection_data; end
end

# Aggregates multiple exceptions.
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/errors.rb#58
class Concurrent::MultipleErrors < ::Concurrent::Error
  # @return [MultipleErrors] a new instance of MultipleErrors
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/errors.rb#61
  def initialize(errors, message = T.unsafe(nil)); end

  # Returns the value of attribute errors.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/errors.rb#59
  def errors; end
end

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic_reference/mutex_atomic.rb#9
class Concurrent::MutexAtomicReference
  include ::Concurrent::AtomicDirectUpdate
  include ::Concurrent::AtomicNumericCompareAndSetWrapper
  extend ::Concurrent::Synchronization::SafeInitialization

  # @param value [Object] The initial value.
  # @return [MutexAtomicReference] a new instance of MutexAtomicReference
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic_reference/mutex_atomic.rb#16
  def initialize(value = T.unsafe(nil)); end

  # Atomically sets the value to the given updated value if
  # the current value == the expected value.
  #
  # that the actual value was not equal to the expected value.
  #
  # @param old_value [Object] the expected value
  # @param new_value [Object] the new value
  # @return [Boolean] `true` if successful. A `false` return indicates
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic_reference/mutex_atomic.rb#45
  def _compare_and_set(old_value, new_value); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic_reference/numeric_cas_wrapper.rb#10
  def compare_and_swap(old_value, new_value); end

  # Gets the current value.
  #
  # @return [Object] the current value
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic_reference/mutex_atomic.rb#23
  def get; end

  # Atomically sets to the given value and returns the old value.
  #
  # @param new_value [Object] the new value
  # @return [Object] the old value
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic_reference/mutex_atomic.rb#35
  def get_and_set(new_value); end

  # Sets to the given value.
  #
  # @param new_value [Object] the new value
  # @return [Object] the new value
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic_reference/mutex_atomic.rb#29
  def set(new_value); end

  # Atomically sets to the given value and returns the old value.
  #
  # @param new_value [Object] the new value
  # @return [Object] the old value
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic_reference/mutex_atomic.rb#35
  def swap(new_value); end

  # Gets the current value.
  #
  # @return [Object] the current value
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic_reference/mutex_atomic.rb#23
  def value; end

  # Sets to the given value.
  #
  # @param new_value [Object] the new value
  # @return [Object] the new value
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic_reference/mutex_atomic.rb#29
  def value=(new_value); end

  protected

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/atomic_reference/mutex_atomic.rb#59
  def synchronize; end
end

# Various classes within allows for +nil+ values to be stored,
# so a special +NULL+ token is required to indicate the "nil-ness".
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/constants.rb#6
Concurrent::NULL = T.let(T.unsafe(nil), Object)

# Suppresses all output when used for logging.
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/concern/logging.rb#103
Concurrent::NULL_LOGGER = T.let(T.unsafe(nil), Proc)

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/options.rb#6
module Concurrent::Options
  class << self
    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/options.rb#27
    def executor(executor_identifier); end

    # Get the requested `Executor` based on the values set in the options hash.
    #
    # @option opts
    # @param opts [Hash] the options defining the requested executor
    # @return [Executor, nil] the requested thread pool, or nil when no option specified
    #
    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/options.rb#19
    def executor_from_options(opts = T.unsafe(nil)); end
  end
end

# Raised by an `Executor` when it is unable to process a given task,
# possibly because of a reject policy or other internal error.
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/errors.rb#48
class Concurrent::RejectedExecutionError < ::Concurrent::Error; end

# Raised when any finite resource, such as a lock counter, exceeds its
# maximum limit/threshold.
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/errors.rb#52
class Concurrent::ResourceLimitError < ::Concurrent::Error; end

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_executor_service.rb#8
class Concurrent::RubyExecutorService < ::Concurrent::AbstractExecutorService
  # @return [RubyExecutorService] a new instance of RubyExecutorService
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_executor_service.rb#11
  def initialize(*args, &block); end

  # Begin an immediate shutdown. In-progress tasks will be allowed to
  # complete but enqueued tasks will be dismissed and no new tasks
  # will be accepted. Has no additional effect if the thread pool is
  # not running.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_executor_service.rb#42
  def kill; end

  # Submit a task to the executor for asynchronous processing.
  #
  # @param args [Array] zero or more arguments to be passed to the task
  # @raise [ArgumentError] if no task is given
  # @return [Boolean] `true` if the task is queued, `false` if the executor
  #   is not running
  # @yield the asynchronous task to perform
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_executor_service.rb#17
  def post(*args, &task); end

  # Begin an orderly shutdown. Tasks already in the queue will be executed,
  # but no new tasks will be accepted. Has no additional effect if the
  # thread pool is not running.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_executor_service.rb#33
  def shutdown; end

  # Block until executor shutdown is complete or until `timeout` seconds have
  # passed.
  #
  # @note Does not initiate shutdown or termination. Either `shutdown` or `kill`
  #   must be called before this method (or on another thread).
  # @param timeout [Integer] the maximum number of seconds to wait for shutdown to complete
  # @return [Boolean] `true` if shutdown complete or false on `timeout`
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_executor_service.rb#52
  def wait_for_termination(timeout = T.unsafe(nil)); end

  private

  # @return [Boolean]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_executor_service.rb#70
  def ns_running?; end

  # @return [Boolean]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_executor_service.rb#78
  def ns_shutdown?; end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_executor_service.rb#66
  def ns_shutdown_execution; end

  # @return [Boolean]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_executor_service.rb#74
  def ns_shuttingdown?; end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_executor_service.rb#58
  def stop_event; end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_executor_service.rb#62
  def stopped_event; end
end

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_single_thread_executor.rb#8
class Concurrent::RubySingleThreadExecutor < ::Concurrent::RubyThreadPoolExecutor
  # @return [RubySingleThreadExecutor] a new instance of RubySingleThreadExecutor
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_single_thread_executor.rb#11
  def initialize(opts = T.unsafe(nil)); end
end

# **Thread Pool Options**
#
# Thread pools support several configuration options:
#
# * `idletime`: The number of seconds that a thread may be idle before being reclaimed.
# * `name`: The name of the executor (optional). Printed in the executor's `#to_s` output and
#   a `<name>-worker-<id>` name is given to its threads if supported by used Ruby
#   implementation. `<id>` is uniq for each thread.
# * `max_queue`: The maximum number of tasks that may be waiting in the work queue at
#   any one time. When the queue size reaches `max_queue` and no new threads can be created,
#   subsequent tasks will be rejected in accordance with the configured `fallback_policy`.
# * `auto_terminate`: When true (default), the threads started will be marked as daemon.
# * `fallback_policy`: The policy defining how rejected tasks are handled.
#
# Three fallback policies are supported:
#
# * `:abort`: Raise a `RejectedExecutionError` exception and discard the task.
# * `:discard`: Discard the task and return false.
# * `:caller_runs`: Execute the task on the calling thread.
#
# **Shutting Down Thread Pools**
#
# Killing a thread pool while tasks are still being processed, either by calling
# the `#kill` method or at application exit, will have unpredictable results. There
# is no way for the thread pool to know what resources are being used by the
# in-progress tasks. When those tasks are killed the impact on those resources
# cannot be predicted. The *best* practice is to explicitly shutdown all thread
# pools using the provided methods:
#
# * Call `#shutdown` to initiate an orderly termination of all in-progress tasks
# * Call `#wait_for_termination` with an appropriate timeout interval an allow
#   the orderly shutdown to complete
# * Call `#kill` *only when* the thread pool fails to shutdown in the allotted time
#
# On some runtime platforms (most notably the JVM) the application will not
# exit until all thread pools have been shutdown. To prevent applications from
# "hanging" on exit, all threads can be marked as daemon according to the
# `:auto_terminate` option.
#
# ```ruby
# pool1 = Concurrent::FixedThreadPool.new(5) # threads will be marked as daemon
# pool2 = Concurrent::FixedThreadPool.new(5, auto_terminate: false) # mark threads as non-daemon
# ```
#
# @note Failure to properly shutdown a thread pool can lead to unpredictable results.
#   Please read *Shutting Down Thread Pools* for more information.
# @see http://docs.oracle.com/javase/tutorial/essential/concurrency/pools.html Java Tutorials: Thread Pools
# @see http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/Executors.html Java Executors class
# @see http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ExecutorService.html Java ExecutorService interface
# @see https://docs.oracle.com/javase/8/docs/api/java/lang/Thread.html#setDaemon-boolean-
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#12
class Concurrent::RubyThreadPoolExecutor < ::Concurrent::RubyExecutorService
  # @return [RubyThreadPoolExecutor] a new instance of RubyThreadPoolExecutor
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#45
  def initialize(opts = T.unsafe(nil)); end

  # The number of threads that are actively executing tasks.
  #
  # @return [Integer] The number of threads that are actively executing tasks.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#65
  def active_count; end

  # Does the task queue have a maximum size?
  #
  # @return [Boolean] True if the task queue has a maximum size else false.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#72
  def can_overflow?; end

  # The number of tasks that have been completed by the pool since construction.
  #
  # @return [Integer] The number of tasks that have been completed by the pool since construction.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#60
  def completed_task_count; end

  # The number of seconds that a thread may be idle before being reclaimed.
  #
  # @return [Integer] The number of seconds that a thread may be idle before being reclaimed.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#36
  def idletime; end

  # The largest number of threads that have been created in the pool since construction.
  #
  # @return [Integer] The largest number of threads that have been created in the pool since construction.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#50
  def largest_length; end

  # The number of threads currently in the pool.
  #
  # @return [Integer] The number of threads currently in the pool.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#77
  def length; end

  # The maximum number of threads that may be created in the pool.
  #
  # @return [Integer] The maximum number of threads that may be created in the pool.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#30
  def max_length; end

  # The maximum number of tasks that may be waiting in the work queue at any one time.
  # When the queue size reaches `max_queue` subsequent tasks will be rejected in
  # accordance with the configured `fallback_policy`.
  #
  # @return [Integer] The maximum number of tasks that may be waiting in the work queue at any one time.
  #   When the queue size reaches `max_queue` subsequent tasks will be rejected in
  #   accordance with the configured `fallback_policy`.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#39
  def max_queue; end

  # The minimum number of threads that may be retained in the pool.
  #
  # @return [Integer] The minimum number of threads that may be retained in the pool.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#33
  def min_length; end

  # Prune the thread pool of unneeded threads
  #
  # What is being pruned is controlled by the min_threads and idletime
  # parameters passed at pool creation time
  #
  # This is a no-op on some pool implementation (e.g. the Java one).  The Ruby
  # pool will auto-prune each time a new job is posted. You will need to call
  # this method explicitely in case your application post jobs in bursts (a
  # lot of jobs and then nothing for long periods)
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#118
  def prune_pool; end

  # The number of tasks in the queue awaiting execution.
  #
  # @return [Integer] The number of tasks in the queue awaiting execution.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#82
  def queue_length; end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#103
  def ready_worker(worker, last_message); end

  # Number of tasks that may be enqueued before reaching `max_queue` and rejecting
  # new tasks. A value of -1 indicates that the queue may grow without bound.
  #
  # @return [Integer] Number of tasks that may be enqueued before reaching `max_queue` and rejecting
  #   new tasks. A value of -1 indicates that the queue may grow without bound.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#87
  def remaining_capacity; end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#98
  def remove_busy_worker(worker); end

  # The number of tasks that have been scheduled for execution on the pool since construction.
  #
  # @return [Integer] The number of tasks that have been scheduled for execution on the pool since construction.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#55
  def scheduled_task_count; end

  # Whether or not a value of 0 for :max_queue option means the queue must perform direct hand-off or rather unbounded queue.
  #
  # @return [true, false]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#42
  def synchronous; end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#108
  def worker_died(worker); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#113
  def worker_task_completed; end

  private

  # creates new worker which has to receive work to do after it's added
  #
  # @return [nil, Worker] nil of max capacity is reached
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#241
  def ns_add_busy_worker; end

  # tries to assign task to a worker, tries to get one from @ready or to create new one
  #
  # @return [true, false] if task is assigned to a worker
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#201
  def ns_assign_worker(*args, &task); end

  # tries to enqueue task
  #
  # @return [true, false] if enqueued
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#219
  def ns_enqueue(*args, &task); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#160
  def ns_execute(*args, &task); end

  # @raise [ArgumentError]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#125
  def ns_initialize(opts); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#189
  def ns_kill_execution; end

  # @return [Boolean]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#155
  def ns_limited_queue?; end

  # try oldest worker if it is idle for enough time, it's returned back at the start
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#280
  def ns_prune_pool; end

  # handle ready worker, giving it new job or assigning back to @ready
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#253
  def ns_ready_worker(worker, last_message, success = T.unsafe(nil)); end

  # removes a worker which is not in not tracked in @ready
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#271
  def ns_remove_busy_worker(worker); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#296
  def ns_reset_if_forked; end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#174
  def ns_shutdown_execution; end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#231
  def ns_worker_died(worker); end
end

# Default maximum number of threads that will be created in the pool.
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#15
Concurrent::RubyThreadPoolExecutor::DEFAULT_MAX_POOL_SIZE = T.let(T.unsafe(nil), Integer)

# Default maximum number of tasks that may be added to the task queue.
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#21
Concurrent::RubyThreadPoolExecutor::DEFAULT_MAX_QUEUE_SIZE = T.let(T.unsafe(nil), Integer)

# Default minimum number of threads that will be retained in the pool.
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#18
Concurrent::RubyThreadPoolExecutor::DEFAULT_MIN_POOL_SIZE = T.let(T.unsafe(nil), Integer)

# Default value of the :synchronous option.
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#27
Concurrent::RubyThreadPoolExecutor::DEFAULT_SYNCHRONOUS = T.let(T.unsafe(nil), FalseClass)

# Default maximum number of seconds a thread in the pool may remain idle
# before being reclaimed.
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#24
Concurrent::RubyThreadPoolExecutor::DEFAULT_THREAD_IDLETIMEOUT = T.let(T.unsafe(nil), Integer)

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#310
class Concurrent::RubyThreadPoolExecutor::Worker
  include ::Logger::Severity
  include ::Concurrent::Concern::Logging

  # @return [Worker] a new instance of Worker
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#313
  def initialize(pool, id); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#324
  def <<(message); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#332
  def kill; end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#328
  def stop; end

  private

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#338
  def create_worker(queue, pool, idletime); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/ruby_thread_pool_executor.rb#358
  def run_task(pool, task, args); end
end

# A simple utility class that executes a callable and returns and array of three elements:
# success - indicating if the callable has been executed without errors
# value - filled by the callable result if it has been executed without errors, nil otherwise
# reason - the error risen by the callable if it has been executed with errors, nil otherwise
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/safe_task_executor.rb#9
class Concurrent::SafeTaskExecutor < ::Concurrent::Synchronization::LockableObject
  # @return [SafeTaskExecutor] a new instance of SafeTaskExecutor
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/safe_task_executor.rb#11
  def initialize(task, opts = T.unsafe(nil)); end

  # @return [Array]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/safe_task_executor.rb#18
  def execute(*args); end
end

# `ScheduledTask` is a close relative of `Concurrent::Future` but with one
# important difference: A `Future` is set to execute as soon as possible
# whereas a `ScheduledTask` is set to execute after a specified delay. This
# implementation is loosely based on Java's
# [ScheduledExecutorService](http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ScheduledExecutorService.html).
# It is a more feature-rich variant of {Concurrent.timer}.
#
# The *intended* schedule time of task execution is set on object construction
# with the `delay` argument. The delay is a numeric (floating point or integer)
# representing a number of seconds in the future. Any other value or a numeric
# equal to or less than zero will result in an exception. The *actual* schedule
# time of task execution is set when the `execute` method is called.
#
# The constructor can also be given zero or more processing options. Currently
# the only supported options are those recognized by the
# [Dereferenceable](Dereferenceable) module.
#
# The final constructor argument is a block representing the task to be performed.
# If no block is given an `ArgumentError` will be raised.
#
# **States**
#
# `ScheduledTask` mixes in the  [Obligation](Obligation) module thus giving it
# "future" behavior. This includes the expected lifecycle states. `ScheduledTask`
# has one additional state, however. While the task (block) is being executed the
# state of the object will be `:processing`. This additional state is necessary
# because it has implications for task cancellation.
#
# **Cancellation**
#
# A `:pending` task can be cancelled using the `#cancel` method. A task in any
# other state, including `:processing`, cannot be cancelled. The `#cancel`
# method returns a boolean indicating the success of the cancellation attempt.
# A cancelled `ScheduledTask` cannot be restarted. It is immutable.
#
# **Obligation and Observation**
#
# The result of a `ScheduledTask` can be obtained either synchronously or
# asynchronously. `ScheduledTask` mixes in both the [Obligation](Obligation)
# module and the
# [Observable](http://ruby-doc.org/stdlib-2.0/libdoc/observer/rdoc/Observable.html)
# module from the Ruby standard library. With one exception `ScheduledTask`
# behaves identically to [Future](Observable) with regard to these modules.
#
# @example Basic usage
#
#   require 'concurrent/scheduled_task'
#   require 'csv'
#   require 'open-uri'
#
#   class Ticker
#   def get_year_end_closing(symbol, year, api_key)
#   uri = "https://www.alphavantage.co/query?function=TIME_SERIES_MONTHLY&symbol=#{symbol}&apikey=#{api_key}&datatype=csv"
#   data = []
#   csv = URI.parse(uri).read
#   if csv.include?('call frequency')
#   return :rate_limit_exceeded
#   end
#   CSV.parse(csv, headers: true) do |row|
#   data << row['close'].to_f if row['timestamp'].include?(year.to_s)
#   end
#   year_end = data.first
#   year_end
#   rescue => e
#   p e
#   end
#   end
#
#   api_key = ENV['ALPHAVANTAGE_KEY']
#   abort(error_message) unless api_key
#
#   # Future
#   price = Concurrent::Future.execute{ Ticker.new.get_year_end_closing('TWTR', 2013, api_key) }
#   price.state #=> :pending
#   price.pending? #=> true
#   price.value(0) #=> nil (does not block)
#
#   sleep(1)    # do other stuff
#
#   price.value #=> 63.65 (after blocking if necessary)
#   price.state #=> :fulfilled
#   price.fulfilled? #=> true
#   price.value #=> 63.65
# @example Successful task execution
#
#   task = Concurrent::ScheduledTask.new(2){ 'What does the fox say?' }
#   task.state         #=> :unscheduled
#   task.execute
#   task.state         #=> pending
#
#   # wait for it...
#   sleep(3)
#
#   task.unscheduled? #=> false
#   task.pending?     #=> false
#   task.fulfilled?   #=> true
#   task.rejected?    #=> false
#   task.value        #=> 'What does the fox say?'
# @example One line creation and execution
#
#   task = Concurrent::ScheduledTask.new(2){ 'What does the fox say?' }.execute
#   task.state         #=> pending
#
#   task = Concurrent::ScheduledTask.execute(2){ 'What do you get when you multiply 6 by 9?' }
#   task.state         #=> pending
# @example Failed task execution
#
#   task = Concurrent::ScheduledTask.execute(2){ raise StandardError.new('Call me maybe?') }
#   task.pending?      #=> true
#
#   # wait for it...
#   sleep(3)
#
#   task.unscheduled? #=> false
#   task.pending?     #=> false
#   task.fulfilled?   #=> false
#   task.rejected?    #=> true
#   task.value        #=> nil
#   task.reason       #=> #<StandardError: Call me maybe?>
# @example Task execution with observation
#
#   observer = Class.new{
#   def update(time, value, reason)
#   puts "The task completed at #{time} with value '#{value}'"
#   end
#   }.new
#
#   task = Concurrent::ScheduledTask.new(2){ 'What does the fox say?' }
#   task.add_observer(observer)
#   task.execute
#   task.pending?      #=> true
#
#   # wait for it...
#   sleep(3)
#
#   #>> The task completed at 2013-11-07 12:26:09 -0500 with value 'What does the fox say?'
# @see Concurrent.timer
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/scheduled_task.rb#158
class Concurrent::ScheduledTask < ::Concurrent::IVar
  include ::Comparable

  # Schedule a task for execution at a specified future time.
  #
  # @option opts
  # @param delay [Float] the number of seconds to wait for before executing the task
  # @param opts [Hash] a customizable set of options
  # @raise [ArgumentError] When no block is given
  # @raise [ArgumentError] When given a time that is in the past
  # @return [ScheduledTask] a new instance of ScheduledTask
  # @yield the task to be performed
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/scheduled_task.rb#178
  def initialize(delay, opts = T.unsafe(nil), &task); end

  # Comparator which orders by schedule time.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/scheduled_task.rb#213
  def <=>(other); end

  # Cancel this task and prevent it from executing. A task can only be
  # cancelled if it is pending or unscheduled.
  #
  # @return [Boolean] true if successfully cancelled else false
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/scheduled_task.rb#235
  def cancel; end

  # Has the task been cancelled?
  #
  # @return [Boolean] true if the task is in the given state else false
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/scheduled_task.rb#220
  def cancelled?; end

  # Execute an `:unscheduled` `ScheduledTask`. Immediately sets the state to `:pending`
  # and starts counting down toward execution. Does nothing if the `ScheduledTask` is
  # in any state other than `:unscheduled`.
  #
  # @return [ScheduledTask] a reference to `self`
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/scheduled_task.rb#273
  def execute; end

  # The executor on which to execute the task.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/scheduled_task.rb#163
  def executor; end

  # The `delay` value given at instanciation.
  #
  # @return [Float] the initial delay.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/scheduled_task.rb#199
  def initial_delay; end

  # Execute the task.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/scheduled_task.rb#297
  def process_task; end

  # In the task execution in progress?
  #
  # @return [Boolean] true if the task is in the given state else false
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/scheduled_task.rb#227
  def processing?; end

  # Reschedule the task using the given delay and the current time.
  # A task can only be reset while it is `:pending`.
  #
  # @param delay [Float] the number of seconds to wait for before executing the task
  # @raise [ArgumentError] When given a time that is in the past
  # @return [Boolean] true if successfully rescheduled else false
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/scheduled_task.rb#262
  def reschedule(delay); end

  # Reschedule the task using the original delay and the current time.
  # A task can only be reset while it is `:pending`.
  #
  # @return [Boolean] true if successfully rescheduled else false
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/scheduled_task.rb#250
  def reset; end

  # The monotonic time at which the the task is scheduled to be executed.
  #
  # @return [Float] the schedule time or nil if `unscheduled`
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/scheduled_task.rb#206
  def schedule_time; end

  protected

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/ivar.rb#135
  def fail(reason = T.unsafe(nil)); end

  # Reschedule the task using the given delay and the current time.
  # A task can only be reset while it is `:pending`.
  #
  # @param delay [Float] the number of seconds to wait for before executing the task
  # @return [Boolean] true if successfully rescheduled else false
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/scheduled_task.rb#326
  def ns_reschedule(delay); end

  # Schedule the task using the given delay and the current time.
  #
  # @param delay [Float] the number of seconds to wait for before executing the task
  # @return [Boolean] true if successfully rescheduled else false
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/scheduled_task.rb#312
  def ns_schedule(delay); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/ivar.rb#113
  def set(value = T.unsafe(nil)); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/ivar.rb#145
  def try_set(value = T.unsafe(nil), &block); end

  class << self
    # Create a new `ScheduledTask` object with the given block, execute it, and return the
    # `:pending` object.
    #
    # @param delay [Float] the number of seconds to wait for before executing the task
    # @raise [ArgumentError] if no block is given
    # @return [ScheduledTask] the newly created `ScheduledTask` in the `:pending` state
    #
    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/scheduled_task.rb#290
    def execute(delay, opts = T.unsafe(nil), &task); end
  end
end

# Indicates that the including `ExecutorService` guarantees
# that all operations will occur in the order they are post and that no
# two operations may occur simultaneously. This module provides no
# functionality and provides no guarantees. That is the responsibility
# of the including class. This module exists solely to allow the including
# object to be interrogated for its serialization status.
#
# @example
#   class Foo
#   include Concurrent::SerialExecutor
#   end
#
#   foo = Foo.new
#
#   foo.is_a? Concurrent::ExecutorService #=> true
#   foo.is_a? Concurrent::SerialExecutor  #=> true
#   foo.serialized?                       #=> true
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/serial_executor_service.rb#24
module Concurrent::SerialExecutorService
  include ::Logger::Severity
  include ::Concurrent::Concern::Logging
  include ::Concurrent::ExecutorService

  # Does this executor guarantee serialization of its operations?
  #
  # @note Always returns `true`
  # @return [Boolean] True if the executor guarantees that all operations
  #   will be post in the order they are received and no two operations may
  #   occur simultaneously. Else false.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/serial_executor_service.rb#30
  def serialized?; end
end

# A thread pool with a single thread an unlimited queue. Should the thread
# die for any reason it will be removed and replaced, thus ensuring that
# the executor will always remain viable and available to process jobs.
#
# A common pattern for background processing is to create a single thread
# on which an infinite loop is run. The thread's loop blocks on an input
# source (perhaps blocking I/O or a queue) and processes each input as it
# is received. This pattern has several issues. The thread itself is highly
# susceptible to errors during processing. Also, the thread itself must be
# constantly monitored and restarted should it die. `SingleThreadExecutor`
# encapsulates all these bahaviors. The task processor is highly resilient
# to errors from within tasks. Also, should the thread die it will
# automatically be restarted.
#
# The API and behavior of this class are based on Java's `SingleThreadExecutor`.
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/single_thread_executor.rb#37
class Concurrent::SingleThreadExecutor < ::Concurrent::RubySingleThreadExecutor; end

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/single_thread_executor.rb#10
Concurrent::SingleThreadExecutorImplementation = Concurrent::RubySingleThreadExecutor

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/abstract_object.rb#2
module Concurrent::Synchronization
  class << self
    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/full_memory_barrier.rb#7
    def full_memory_barrier; end
  end
end

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/abstract_lockable_object.rb#9
class Concurrent::Synchronization::AbstractLockableObject < ::Concurrent::Synchronization::Object
  protected

  # Broadcast to all waiting threads.
  #
  # @note only to be used inside synchronized block
  # @note to provide direct access to this method in a descendant add method
  #   ```
  #   def broadcast
  #   synchronize { ns_broadcast }
  #   end
  #   ```
  # @raise [NotImplementedError]
  # @return [self]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/abstract_lockable_object.rb#96
  def ns_broadcast; end

  # Signal one waiting thread.
  #
  # @note only to be used inside synchronized block
  # @note to provide direct access to this method in a descendant add method
  #   ```
  #   def signal
  #   synchronize { ns_signal }
  #   end
  #   ```
  # @raise [NotImplementedError]
  # @return [self]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/abstract_lockable_object.rb#81
  def ns_signal; end

  # Wait until another thread calls #signal or #broadcast,
  # spurious wake-ups can happen.
  #
  # @note only to be used inside synchronized block
  # @note to provide direct access to this method in a descendant add method
  #   ```
  #   def wait(timeout = nil)
  #   synchronize { ns_wait(timeout) }
  #   end
  #   ```
  # @param timeout [Numeric, nil] in seconds, `nil` means no timeout
  # @raise [NotImplementedError]
  # @return [self]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/abstract_lockable_object.rb#66
  def ns_wait(timeout = T.unsafe(nil)); end

  # Wait until condition is met or timeout passes,
  # protects against spurious wake-ups.
  #
  # @note only to be used inside synchronized block
  # @note to provide direct access to this method in a descendant add method
  #   ```
  #   def wait_until(timeout = nil, &condition)
  #   synchronize { ns_wait_until(timeout, &condition) }
  #   end
  #   ```
  # @param timeout [Numeric, nil] in seconds, `nil` means no timeout
  # @return [true, false] if condition met
  # @yield condition to be met
  # @yieldreturn [true, false]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/abstract_lockable_object.rb#37
  def ns_wait_until(timeout = T.unsafe(nil), &condition); end

  # @note can by made public in descendants if required by `public :synchronize`
  # @raise [NotImplementedError]
  # @yield runs the block synchronized against this object,
  #   equivalent of java's `synchronize(this) {}`
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/abstract_lockable_object.rb#18
  def synchronize; end
end

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/abstract_object.rb#6
class Concurrent::Synchronization::AbstractObject
  # @return [AbstractObject] a new instance of AbstractObject
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/abstract_object.rb#7
  def initialize; end

  # @abstract
  # @raise [NotImplementedError]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/abstract_object.rb#13
  def full_memory_barrier; end

  class << self
    # @raise [NotImplementedError]
    #
    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/abstract_object.rb#17
    def attr_volatile(*names); end
  end
end

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/mutex_lockable_object.rb#8
module Concurrent::Synchronization::ConditionSignalling
  protected

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/mutex_lockable_object.rb#16
  def ns_broadcast; end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/mutex_lockable_object.rb#11
  def ns_signal; end
end

# Safe synchronization under any Ruby implementation.
#   It provides methods like {#synchronize}, {#wait}, {#signal} and {#broadcast}.
#   Provides a single layer which can improve its implementation over time without changes needed to
#   the classes using it. Use {Synchronization::Object} not this abstract class.
#
#   @note this object does not support usage together with
#     [`Thread#wakeup`](http://ruby-doc.org/core/Thread.html#method-i-wakeup)
#     and [`Thread#raise`](http://ruby-doc.org/core/Thread.html#method-i-raise).
#     `Thread#sleep` and `Thread#wakeup` will work as expected but mixing `Synchronization::Object#wait` and
#     `Thread#wakeup` will not work on all platforms.
#
#   @see Event implementation as an example of this class use
#
#   @example simple
#     class AnClass < Synchronization::Object
#       def initialize
#         super
#         synchronize { @value = 'asd' }
#       end
#
#       def value
#         synchronize { @value }
#       end
#     end
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/lockable_object.rb#50
class Concurrent::Synchronization::LockableObject < ::Concurrent::Synchronization::MutexLockableObject; end

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/lockable_object.rb#11
Concurrent::Synchronization::LockableObjectImplementation = Concurrent::Synchronization::MutexLockableObject

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/mutex_lockable_object.rb#60
class Concurrent::Synchronization::MonitorLockableObject < ::Concurrent::Synchronization::AbstractLockableObject
  include ::Concurrent::Synchronization::ConditionSignalling
  extend ::Concurrent::Synchronization::SafeInitialization

  # @return [MonitorLockableObject] a new instance of MonitorLockableObject
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/mutex_lockable_object.rb#65
  def initialize; end

  protected

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/mutex_lockable_object.rb#83
  def ns_wait(timeout = T.unsafe(nil)); end

  # TODO may be a problem with lock.synchronize { lock.wait }
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/mutex_lockable_object.rb#79
  def synchronize; end

  private

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/mutex_lockable_object.rb#71
  def initialize_copy(other); end
end

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/mutex_lockable_object.rb#25
class Concurrent::Synchronization::MutexLockableObject < ::Concurrent::Synchronization::AbstractLockableObject
  include ::Concurrent::Synchronization::ConditionSignalling
  extend ::Concurrent::Synchronization::SafeInitialization

  # @return [MutexLockableObject] a new instance of MutexLockableObject
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/mutex_lockable_object.rb#30
  def initialize; end

  protected

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/mutex_lockable_object.rb#52
  def ns_wait(timeout = T.unsafe(nil)); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/mutex_lockable_object.rb#44
  def synchronize; end

  private

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/mutex_lockable_object.rb#36
  def initialize_copy(other); end
end

# Abstract object providing final, volatile, ans CAS extensions to build other concurrent abstractions.
# - final instance variables see {Object.safe_initialization!}
# - volatile instance variables see {Object.attr_volatile}
# - volatile instance variables see {Object.attr_atomic}
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/object.rb#15
class Concurrent::Synchronization::Object < ::Concurrent::Synchronization::AbstractObject
  include ::Concurrent::Synchronization::Volatile
  extend ::Concurrent::Synchronization::Volatile::ClassMethods

  # Has to be called by children.
  #
  # @return [Object] a new instance of Object
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/object.rb#28
  def initialize; end

  private

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/object.rb#146
  def __initialize_atomic_fields__; end

  class << self
    # @return [true, false] is the attribute with name atomic?
    #
    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/object.rb#125
    def atomic_attribute?(name); end

    # @param inherited [true, false] should inherited volatile with CAS fields be returned?
    # @return [::Array<Symbol>] Returns defined volatile with CAS fields on this class.
    #
    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/object.rb#119
    def atomic_attributes(inherited = T.unsafe(nil)); end

    # Creates methods for reading and writing to a instance variable with
    # volatile (Java) semantic as {.attr_volatile} does.
    # The instance variable should be accessed oly through generated methods.
    # This method generates following methods: `value`, `value=(new_value) #=> new_value`,
    # `swap_value(new_value) #=> old_value`,
    # `compare_and_set_value(expected, value) #=> true || false`, `update_value(&block)`.
    #
    # @param names [::Array<Symbol>] of the instance variables to be volatile with CAS.
    # @return [::Array<Symbol>] names of defined method names.
    #
    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/object.rb#84
    def attr_atomic(*names); end

    # For testing purposes, quite slow. Injects assert code to new method which will raise if class instance contains
    # any instance variables with CamelCase names and isn't {.safe_initialization?}.
    #
    # @raise when offend found
    # @return [true]
    #
    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/object.rb#45
    def ensure_safe_initialization_when_final_fields_are_present; end

    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/object.rb#33
    def safe_initialization!; end

    # @return [Boolean]
    #
    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/object.rb#37
    def safe_initialization?; end

    private

    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/object.rb#131
    def define_initialize_atomic_fields; end
  end
end

# By extending this module, a class and all its children are marked to be constructed safely. Meaning that
# all writes (ivar initializations) are made visible to all readers of newly constructed object. It ensures
# same behaviour as Java's final fields.
#
# Due to using Kernel#extend, the module is not included again if already present in the ancestors,
# which avoids extra overhead.
#
# @example
#   class AClass < Concurrent::Synchronization::Object
#   extend Concurrent::Synchronization::SafeInitialization
#
#   def initialize
#   @AFinalValue = 'value' # published safely, #foo will never return nil
#   end
#
#   def foo
#   @AFinalValue
#   end
#   end
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/safe_initialization.rb#28
module Concurrent::Synchronization::SafeInitialization
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/safe_initialization.rb#29
  def new(*args, &block); end
end

# Volatile adds the attr_volatile class method when included.
#
#  foo = Foo.new
#  foo.bar
#  => 1
#  foo.bar = 2
#  => 2
#
# @example
#   class Foo
#   include Concurrent::Synchronization::Volatile
#
#   attr_volatile :bar
#
#   def initialize
#   self.bar = 1
#   end
#   end
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/volatile.rb#28
module Concurrent::Synchronization::Volatile
  mixes_in_class_methods ::Concurrent::Synchronization::Volatile::ClassMethods

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/volatile.rb#33
  def full_memory_barrier; end

  class << self
    # @private
    #
    # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/volatile.rb#29
    def included(base); end
  end
end

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/volatile.rb#37
module Concurrent::Synchronization::Volatile::ClassMethods
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/synchronization/volatile.rb#39
  def attr_volatile(*names); end
end

# An abstraction composed of one or more threads and a task queue. Tasks
# (blocks or `proc` objects) are submitted to the pool and added to the queue.
# The threads in the pool remove the tasks and execute them in the order
# they were received.
#
# A `ThreadPoolExecutor` will automatically adjust the pool size according
# to the bounds set by `min-threads` and `max-threads`. When a new task is
# submitted and fewer than `min-threads` threads are running, a new thread
# is created to handle the request, even if other worker threads are idle.
# If there are more than `min-threads` but less than `max-threads` threads
# running, a new thread will be created only if the queue is full.
#
# Threads that are idle for too long will be garbage collected, down to the
# configured minimum options. Should a thread crash it, too, will be garbage collected.
#
# `ThreadPoolExecutor` is based on the Java class of the same name. From
# the official Java documentation;
#
# > Thread pools address two different problems: they usually provide
# > improved performance when executing large numbers of asynchronous tasks,
# > due to reduced per-task invocation overhead, and they provide a means
# > of bounding and managing the resources, including threads, consumed
# > when executing a collection of tasks. Each ThreadPoolExecutor also
# > maintains some basic statistics, such as the number of completed tasks.
# >
# > To be useful across a wide range of contexts, this class provides many
# > adjustable parameters and extensibility hooks. However, programmers are
# > urged to use the more convenient Executors factory methods
# > [CachedThreadPool] (unbounded thread pool, with automatic thread reclamation),
# > [FixedThreadPool] (fixed size thread pool) and [SingleThreadExecutor] (single
# > background thread), that preconfigure settings for the most common usage
# > scenarios.
#
# **Thread Pool Options**
#
# Thread pools support several configuration options:
#
# * `idletime`: The number of seconds that a thread may be idle before being reclaimed.
# * `name`: The name of the executor (optional). Printed in the executor's `#to_s` output and
#   a `<name>-worker-<id>` name is given to its threads if supported by used Ruby
#   implementation. `<id>` is uniq for each thread.
# * `max_queue`: The maximum number of tasks that may be waiting in the work queue at
#   any one time. When the queue size reaches `max_queue` and no new threads can be created,
#   subsequent tasks will be rejected in accordance with the configured `fallback_policy`.
# * `auto_terminate`: When true (default), the threads started will be marked as daemon.
# * `fallback_policy`: The policy defining how rejected tasks are handled.
#
# Three fallback policies are supported:
#
# * `:abort`: Raise a `RejectedExecutionError` exception and discard the task.
# * `:discard`: Discard the task and return false.
# * `:caller_runs`: Execute the task on the calling thread.
#
# **Shutting Down Thread Pools**
#
# Killing a thread pool while tasks are still being processed, either by calling
# the `#kill` method or at application exit, will have unpredictable results. There
# is no way for the thread pool to know what resources are being used by the
# in-progress tasks. When those tasks are killed the impact on those resources
# cannot be predicted. The *best* practice is to explicitly shutdown all thread
# pools using the provided methods:
#
# * Call `#shutdown` to initiate an orderly termination of all in-progress tasks
# * Call `#wait_for_termination` with an appropriate timeout interval an allow
#   the orderly shutdown to complete
# * Call `#kill` *only when* the thread pool fails to shutdown in the allotted time
#
# On some runtime platforms (most notably the JVM) the application will not
# exit until all thread pools have been shutdown. To prevent applications from
# "hanging" on exit, all threads can be marked as daemon according to the
# `:auto_terminate` option.
#
# ```ruby
# pool1 = Concurrent::FixedThreadPool.new(5) # threads will be marked as daemon
# pool2 = Concurrent::FixedThreadPool.new(5, auto_terminate: false) # mark threads as non-daemon
# ```
#
# @note Failure to properly shutdown a thread pool can lead to unpredictable results.
#   Please read *Shutting Down Thread Pools* for more information.
# @see http://docs.oracle.com/javase/tutorial/essential/concurrency/pools.html Java Tutorials: Thread Pools
# @see http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/Executors.html Java Executors class
# @see http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ExecutorService.html Java ExecutorService interface
# @see https://docs.oracle.com/javase/8/docs/api/java/lang/Thread.html#setDaemon-boolean-
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/thread_pool_executor.rb#56
class Concurrent::ThreadPoolExecutor < ::Concurrent::RubyThreadPoolExecutor; end

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/thread_pool_executor.rb#10
Concurrent::ThreadPoolExecutorImplementation = Concurrent::RubyThreadPoolExecutor

# Raised when an operation times out.
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/errors.rb#55
class Concurrent::TimeoutError < ::Concurrent::Error; end

# Executes a collection of tasks, each after a given delay. A master task
# monitors the set and schedules each task for execution at the appropriate
# time. Tasks are run on the global thread pool or on the supplied executor.
# Each task is represented as a `ScheduledTask`.
#
# @see Concurrent::ScheduledTask
#
# source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/timer_set.rb#19
class Concurrent::TimerSet < ::Concurrent::RubyExecutorService
  # Create a new set of timed tasks.
  #
  # @option opts
  # @param opts [Hash] the options used to specify the executor on which to perform actions
  # @return [TimerSet] a new instance of TimerSet
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/timer_set.rb#30
  def initialize(opts = T.unsafe(nil)); end

  # Begin an immediate shutdown. In-progress tasks will be allowed to
  # complete but enqueued tasks will be dismissed and no new tasks
  # will be accepted. Has no additional effect if the thread pool is
  # not running.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/timer_set.rb#62
  def kill; end

  # Post a task to be execute run after a given delay (in seconds). If the
  # delay is less than 1/100th of a second the task will be immediately post
  # to the executor.
  #
  # @param delay [Float] the number of seconds to wait for before executing the task.
  # @param args [Array<Object>] the arguments passed to the task on execution.
  # @raise [ArgumentError] if the intended execution time is not in the future.
  # @raise [ArgumentError] if no block is given.
  # @return [Concurrent::ScheduledTask, false] IVar representing the task if the post
  #   is successful; false after shutdown.
  # @yield the task to be performed.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/timer_set.rb#48
  def post(delay, *args, &task); end

  private

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/executor_service.rb#166
  def <<(task); end

  # Initialize the object.
  #
  # @param opts [Hash] the options to create the object with.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/timer_set.rb#74
  def ns_initialize(opts); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/timer_set.rb#94
  def ns_post_task(task); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/timer_set.rb#129
  def ns_reset_if_forked; end

  # `ExecutorService` callback called during shutdown.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/timer_set.rb#122
  def ns_shutdown_execution; end

  # Post the task to the internal queue.
  #
  # @note This is intended as a callback method from ScheduledTask
  #   only. It is not intended to be used directly. Post a task
  #   by using the `SchedulesTask#execute` method.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/timer_set.rb#89
  def post_task(task); end

  # Run a loop and execute tasks in the scheduled order and at the approximate
  # scheduled time. If no tasks remain the thread will exit gracefully so that
  # garbage collection can occur. If there are no ready tasks it will sleep
  # for up to 60 seconds waiting for the next scheduled task.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/timer_set.rb#143
  def process_tasks; end

  # Remove the given task from the queue.
  #
  # @note This is intended as a callback method from `ScheduledTask`
  #   only. It is not intended to be used directly. Cancel a task
  #   by using the `ScheduledTask#cancel` method.
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/executor/timer_set.rb#115
  def remove_task(task); end
end

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/engine.rb#3
module Concurrent::Utility; end

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/engine.rb#6
module Concurrent::Utility::EngineDetector
  # @return [Boolean]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/engine.rb#7
  def on_cruby?; end

  # @return [Boolean]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/engine.rb#11
  def on_jruby?; end

  # @return [Boolean]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/engine.rb#27
  def on_linux?; end

  # @return [Boolean]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/engine.rb#23
  def on_osx?; end

  # @return [Boolean]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/engine.rb#15
  def on_truffleruby?; end

  # @return [Boolean]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/engine.rb#19
  def on_windows?; end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/engine.rb#31
  def ruby_version(version = T.unsafe(nil), comparison, major, minor, patch); end
end

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/native_extension_loader.rb#9
module Concurrent::Utility::NativeExtensionLoader
  # @return [Boolean]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/native_extension_loader.rb#11
  def allow_c_extensions?; end

  # @return [Boolean]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/native_extension_loader.rb#15
  def c_extensions_loaded?; end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/native_extension_loader.rb#19
  def load_native_extensions; end

  private

  # @return [Boolean]
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/native_extension_loader.rb#50
  def java_extensions_loaded?; end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/native_extension_loader.rb#38
  def load_error_path(error); end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/native_extension_loader.rb#46
  def set_c_extensions_loaded; end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/native_extension_loader.rb#54
  def set_java_extensions_loaded; end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/native_extension_loader.rb#58
  def try_load_c_extension(path); end
end

# source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/processor_counter.rb#10
class Concurrent::Utility::ProcessorCounter
  # @return [ProcessorCounter] a new instance of ProcessorCounter
  #
  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/processor_counter.rb#11
  def initialize; end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/processor_counter.rb#20
  def physical_processor_count; end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/processor_counter.rb#16
  def processor_count; end

  private

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/processor_counter.rb#34
  def compute_physical_processor_count; end

  # source://concurrent-ruby//lib/concurrent-ruby/concurrent/utility/processor_counter.rb#26
  def compute_processor_count; end
end
